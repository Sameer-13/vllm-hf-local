{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# vLLM with Llama-3.2-1B-it for Reveiw Sentiment Analysis"
      ],
      "metadata": {
        "id": "__8crnA-n060"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup"
      ],
      "metadata": {
        "id": "lvRAO94HoDLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7QNPLsLnTr-"
      },
      "outputs": [],
      "source": [
        "!pip install -q vllm\n",
        "!pip install -q -U \"huggingface_hub[cli]\"\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"ipython>=8.20\" \"jedi>=0.19\"\n",
        "!pip check    # shows any remaining dependency issues"
      ],
      "metadata": {
        "id": "mpge6W3VXed5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! hf auth login"
      ],
      "metadata": {
        "id": "fxDLLXlZoIYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configeration"
      ],
      "metadata": {
        "id": "KfesN7HQg3i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "api_key = \"tokenX\""
      ],
      "metadata": {
        "id": "6McWFcsRg7U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop any old servers\n",
        "!pkill -f \"vllm serve\" || true\n",
        "\n",
        "# Run in background\n",
        "!nohup vllm serve $model \\\n",
        "  --host 127.0.0.1 \\\n",
        "  --port 8000 \\\n",
        "  --dtype auto \\\n",
        "  --api-key $api_key &"
      ],
      "metadata": {
        "id": "nip8O2uty4Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  # quick peek at the last lines of the log (non-blocking)\n",
        "  !sleep 2; tail -n 30 nohup.out"
      ],
      "metadata": {
        "id": "cl2nWrI6dc3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Testing Reachability"
      ],
      "metadata": {
        "id": "jAn7OgeGfTl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, httpx, subprocess\n",
        "\n",
        "BASE_URL = \"http://127.0.0.1:8000/v1\"\n",
        "HEADERS  = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "ready = False\n",
        "for i in range(180):  # up to ~3 minutes on first load\n",
        "    try:\n",
        "        # 1) unauthenticated health probe\n",
        "        if httpx.get(\"http://127.0.0.1:8000/health\", timeout=1.0).status_code == 200:\n",
        "            # 2) authenticated check on /v1/models\n",
        "            r = httpx.get(f\"{BASE_URL}/models\", headers=HEADERS, timeout=2.0)\n",
        "            if r.status_code == 200:\n",
        "                print(\"vLLM is ready ✅\")\n",
        "                ready = True\n",
        "                break\n",
        "    except Exception:\n",
        "        pass\n",
        "    if i % 10 == 0:\n",
        "        print(\"waiting for vLLM…\")\n",
        "    time.sleep(1)\n",
        "\n",
        "if not ready:\n",
        "    print(\"Server not ready. Recent logs:\")\n",
        "    print(subprocess.run([\"bash\",\"-lc\",\"tail -n 80 nohup.out\"], capture_output=True, text=True).stdout)"
      ],
      "metadata": {
        "id": "xNPqGvqyfTYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Inferencing"
      ],
      "metadata": {
        "id": "UUp2Og8Sop3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "review_text = \"الطعام لذيذ والشيش افضل شيش ذقته روعه ويحتاج فقط اعاده تأهيل المبنى والتوسعه\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are given a customer review in Arabic.\n",
        "Evaluate how satisfied the customer seems with the place, its condition, and its services.\n",
        "Output a single integer score from 1 to 10, where:\n",
        "1 = very unhappy and dissatisfied\n",
        "10 = extremely happy and satisfied\n",
        "\n",
        "ONLY output the integer, nothing else.\n",
        "\n",
        "Review: {review_text}\n",
        "\"\"\"\n",
        "\n",
        "client = OpenAI(base_url=BASE_URL, api_key=api_key)\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=3,\n",
        ")\n",
        "\n",
        "predicted_rating = resp.choices[0].message.content.strip()\n",
        "print(predicted_rating)\n"
      ],
      "metadata": {
        "id": "HgsJE3CFpU5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}